<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />

<title>Junjie Wang</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai Zhang</h1>
</div>
 -->


<table class="imgtable"><tr><td>
<a href="./"><img src="./files/jjwang_new.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><font size="4">Junjie Wang (王俊杰)</font><br />
<br />
<!--
<a href="https://vision.ee.ethz.ch/the-institute.html">Computer Vision Lab</a><br />
 Department of Information Technology and Electrical Engineering, <a href="https://ethz.ch/en.html" target="_blank">ETH Zurich</a><br />
-->
<br />
School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China<br />

<br />
Email: jjwang@bupt.edu.cn  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   junjiewang1218@gmail.com <br />
[<a class="p1" href="https://scholar.google.com/citations?user=vJlZY-gAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>] [<a class="p2" href="https://github.com/jie040109" target="_blank">Github</a>]

</td></tr></table>


  

	
<h2>Biography</h2>
<p>I am a fourth-year undergraduate student at Beijing University of Posts and Telecommunications. 
  During my undergraduate studies, I worked closely with Prof. <a href="https://dblp.org/pid/222/3004.html">Qicheng Lao</a>.
  </p>


<h2>Research Interest</h2>
My core research interest lies in developing truly intelligent systems through the application of machine learning theory.
Recently, I focus on the following research topics:
<ul>
<li>Parameter-Efficient Fine-Tuning of Large Pre-trained Models</li>
<li>Efficient Training of Large Language Models</li>


</ul>


<!-- 	
<h2>PyTorch Toolbox for Image Restoration</h2>
<ul>
<li> <a href="https://github.com/cszn/KAIR" target="_blank">KAIR</a> (support training and testing for DnCNN, FFDNet, SRMD, USRNet, ESRGAN) </li>
<li> <a href="https://github.com/cszn/DPIR" target="_blank">DPIR</a> (Plug-and-Play Image Restoration with Deep Denoiser Prior)</li>
</ul> -->


<h2>News</h2>
<ul>
  <li><span style="color: red;"><strong>(2024-9.29) I will be enrolled in Peking University to pursue a doctorate degree in September 2025, with  Prof. </Link> <a href="https://zhouchenlin.github.io/">Zhouchen Lin</a> as my supervisor!</strong></span></li>
  <li><span style="color: red;"><strong>(2024-09.26) One paper is accepted in NeurIPS 2024!</strong></span></li>
<!-- <li>(2024-06) I will serve as a Senior Program Committee (SPC) Member for AAAI 2025.
<li>We are organizing a Special Issue titled <a href="https://link.springer.com/collections/fbihijbidh" target="_blank">"Recent Advances in Image Reconstruction"</a> for Visual Intelligence. Submissions of high-quality articles are warmly welcome.
<li>Four papers are accepted in CVPR 2024.
<li>(2022-07) I will serve as a Senior Program Committee (SPC) Member for AAAI 2023.
<li>I am organizing a Special Issue <a href="https://www.mdpi.com/journal/sensors/special_issues/idisrsa_sensors" target="_blank">"Image Denoising and Image Super-Resolution for Sensing Application"</a> on Sensors (IF 3.576), submit your manuscript before 15 December 2022.
<li>We released the testing codes of <a href="https://github.com/cszn/SCUNet" target="_blank">SCUNet</a>.</li>
<li>We released the training codes of <a href="https://github.com/cszn/BSRNet" target="_blank">BSRNet</a> and <a href="https://github.com/cszn/KAIR/blob/master/docs/README_SwinIR.md" target="_blank">SwinIR</a>.</li>
<li><b>All the four submitted papers are accepted by ICCV 2021. Congratulations to Jingyun Liang and Jiaxi Jiang.</b>
<li>One paper is accepted by IEEE TPAMI.</li>
<li>Two papers are accepted in CVPR 2021.</li>
<li>The code of <a href="https://github.com/cszn/BSRNet" target="_blank">BSRNet</a> is available.</li>
<li>The code of <a href="https://github.com/cszn/DPIR" target="_blank">DPIR</a> is available.</li>
<li>The code of <a href="https://github.com/cszn/USRNet" target="_blank">USRNet</a> is available.</li>
<li>I am co-organizing the ECCV 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank">Advances in Image Manipulation</a></li>

<li>I am co-organizing the CVPR 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/ntire20/" target="_blank">New Trends in Image Restoration and Enhancement</a></li> -->
</ul>

	
<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">

<!-- NeurIPS 2024-->
<tr>
<td><img class="proj_thumb" src="./files/MLAE.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">MLAE: Masked LoRA Experts for Visual Parameter-Efficient Fine-Tuning</p>
<p class="pub_author"><b>Junjie Wang*</b>, Guangjing Yang*, Wentao Chen, Huahui Yi, Xiaohu Wu, Zhouchen Lin, Qicheng Lao<br>
  Arxiv Tech Report, 2024<br>
[<a href= "https://arxiv.org/pdf/2405.18897" target="_blank">Paper</a>] 
[<a href="https://github.com/jie040109/MLAE" target="_blank">PyTorch Code</a>] 
</p> </td>
</tr>

<!-- NeurIPS 2024-->
<tr>
  <td><img class="proj_thumb" src="./files/LCL.png" alt="" height="100px"/>&nbsp;</td>
  <td>
  <p class="pub_title">Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning</p>
  <p class="pub_author">Chenyu Yang*, Xizhou Zhu*, Jinguo Zhu*, Weijie Su, <b>Junjie Wang</b>, Xuan Dong, Wenhai Wang, Lewei Lu, Bin Li, Jie Zhou, Yu Qiao, Jifeng Dai<br>
 <b>NeurIPS 2024</b> <br>
  [<a href= "https://arxiv.org/pdf/2406.07543" target="_blank">Paper</a>] 
  [<a href="https://github.com/OpenGVLab/LCL" target="_blank">PyTorch Code</a>] 
  </p> </td>
  </tr>


<table>

<!-- Services -->
<!-- <a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Workshop Organizers: </p>
<font size="2">
<ul>
<li><p>Co-organizer of ECCV 2020 Workshop on Advanced Image Manipulation (AIM). </p></li>
<li><p>Co-organizer of CVPR 2020 Workshop on New Trends in Image Restoration and Enhancement (NTIRE). </p></li>
<li><p>Co-organizer of ICCV 2019 Workshop on Advanced Image Manipulation (AIM). </p></li>
</ul>
</font>


 
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<li>International Journal of Computer Vision (IJCV)</li>
<li>IEEE Transactions on Image Processing (TIP)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
<li>Computer Vision and Image Understanding (CVIU)</li>
<li>Signal Processing Letters (SPL)</li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>AAAI Conference on Artificial Intelligence (AAAI)</li>
<li>International Joint Conferences on Artificial Intelligence (IJCAI)</li>
</ul>
</font> -->

<!-- students -->
<!-- <a id="students" class="achor"></a>
<h2>Students Co-supervised</h2>
<p>PhD students: </p>
<font size="2">
<ul>
<li><p><a href="https://jingyunliang.github.io/" target="_blank">Jingyun Liang</a>, 2019/11 - 2024/01 </p></li>
<li><p><a href="https://www.jiezhangcao.com/" target="_blank">Jiezhang Cao</a>, 2020/11 - 2024/05 </p></li>
</ul>
</font>	

<p>Master students: </p>
<font size="2"> 
<ul>
<li><a href="https://yuanzhi-zhu.github.io/about/" target="_blank">Yuanzhi Zhu</a>, 2022/07 - 2023/06</li>
<li><a href="https://jiaxi-jiang.com/" target="_blank">Jiaxi Jiang</a>, 2020/09 - 2021/05</li>
</ul>
</font>	 -->


<!-- awards -->
<!-- <a id="awards" class="achor"></a>
<h2>Awards</h2>
<font size="2"> 
<ul>
<li>Excellent Doctoral Dissertation of HIT, 2021</li>
<li>First Prize of Natural Science Award of Heilongjiang Province, 2020</li>
<li>Outstanding student paper award of HIT, 2018</li>
<li>Fourth place of NTIRE 2018 challenge on single image super-resolution, 2018</li>
<li>National scholarship for doctoral students, 2017</li>
<li>Outstanding student paper award of HIT, 2017</li>
<li>First prize of GUANGXI International Academic Forum, 2017</li>
<li>Best poster award of Valse2017, 2017</li>
</ul>
</font> -->


<!-- Links -->
<!-- <h2>Collaborators</h2>
<ul>
<a href= "http://people.ee.ethz.ch/~timofter/" target="_blank">Radu Timofte</a>, &nbsp
<a href= "https://sites.google.com/site/shuhanggu/" target="_blank">Shuhang Gu</a>, &nbsp
<a href= "https://csdwren.github.io/" target="_blank">Dongwei Ren</a>, &nbsp
<a href= "https://kedema.org/" target="_blank">Kede Ma</a>, &nbsp
<a href= "https://sites.google.com/view/yonghongwei-homepage" target="_blank">Hongwei Yong</a>
</ul> -->

<!-- Links 
<h2>Music</h2>
<iframe width="280" height="157" src="https://www.youtube.com/embed/-5qhNRmMilI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
<iframe width="280" height="157" src="https://www.youtube.com/embed/AVXejOoPECA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="280" height="157" src="https://www.youtube.com/embed/xTRVZbHjmbc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
-->
	
	
	
<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
